## Coding Skills
### Languages
- Python (6 years)
- C/C++ (4 years), Fortran (4 years), 
- Java (3 years), C# (2 years), MySQL (2 years)

### Machine Learning, AI and Data-Analysis: 
(Un)supervised- and reinforcement learning, and generative models.

Frameworks and libraries: 
[Keras](https://keras.io/), 
[Pytorch](https://pytorch.org/), 
[OpenAI Gym](https://gym.openai.com/),
[RLLib](https://docs.ray.io/en/latest/rllib.html),
[estools](https://github.com/estools), 
[NEAT](https://neat-python.readthedocs.io/en/latest/),
[scikit-learn](https://scikit-learn.org/),
[Pandas](https://pandas.pydata.org/).

### Numerics & Optimization:
Non-linear optimization and statistical tools, such as (replica exchange) Monte Carlo.

Libraries and tools:
[NumPy](https://numpy.org/),
[SciPy](https://scipy.org/),
[OpenCV](https://opencv.org/),
[Scipy-optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html),
[Monte-Carlo optimization](https://de.wikipedia.org/wiki/Monte-Carlo-Simulation), 
[Replica exchange Monte Carlo](https://en.wikipedia.org/wiki/Parallel_tempering)


### High-Performance Computing and Accelerators
Six(+) years of experience working with supercomputers (versions 2, 3 and 4 of the [Vienna Scientific Cluster](https://www.vsc.ac.at/home/); [JURECA](https://www.fz-juelich.de/ias/jsc/EN/Expertise/Supercomputers/JURECA/JURECA_node.html)) using [slurm](https://slurm.schedmd.com/documentation.html).

Nvidia-GPU usage via tensorflow, PyTorch or Numba.

Libraries and tools:
[MPI](https://www.open-mpi.org/),
[OpenMP](https://www.vsc.ac.at/home/),
[Threading](https://docs.python.org/3/library/threading.html),
[multiprocessing](https://docs.python.org/3/library/multiprocessing.html),
[Numba](https://numba.pydata.org/).

### Interfacing:
Especially during my Ph.D., I could profit from legacy code provided by my host-group, or the science community (mostly written in Fortran or C++).
Python is a great language for maintaining projects, but being an interpreted language, it is considerably less performant than compiled code (if not used appropriately).
By compiling highly-performant (legacy) code as Python modules, we can have the best of both worlds: performant code which is easy to maintain.

Libraries and Tools:
[F2PY](https://numpy.org/doc/stable/f2py/),
[Boost-Python](https://www.boost.org/doc/libs/1_63_0/libs/python/doc/html/index.html),
[Lab-Streaming-Layer](https://labstreaminglayer.readthedocs.io/info/intro.html).

### IO:
- Monitoring Keras or PyTorch models: [TensorBoard](https://www.tensorflow.org/tensorboard)
- Framework config-files: [yaml](https://yaml.org/), [json](https://www.json.org/json-en.html)
- Fast IO and processing of heterogeneous data: [hdf5](https://www.hdfgroup.org/solutions/hdf5/)

### Code-Maintenance:
- Containerization: [Docker](https://www.docker.com/), [venv](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)
- Documentation: [Docstrings](https://www.python.org/dev/peps/pep-0257/), [Markdown](https://daringfireball.net/projects/markdown/)
- Testing: [Unittests](https://docs.python.org/3/library/unittest.html)

### IDE and Tools: 
- PyCharm, Eclipse, Jupyter, git
- LaTex, Gimp, Inkscape, Blender
